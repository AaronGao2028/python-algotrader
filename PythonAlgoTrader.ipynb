{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e2c527-caa5-4fd9-8643-db682d89ade0",
   "metadata": {},
   "source": [
    "# Python AlgoTrader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88728f7-533a-4492-9352-61c891a324af",
   "metadata": {},
   "source": [
    "### Created By: Aaron Gao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593a096-8ebf-4d95-8db9-ef767bb09d87",
   "metadata": {},
   "source": [
    "Python AlgoTrader is an automated trading system that executes orders based on the crossover of the 50 minute and 200 minute moving average. By searching for the iconic Golden Cross and the infamous Death Cross, intraday traders can find great opportunities by riding out the momentum on breakout trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37eabd",
   "metadata": {},
   "source": [
    "We will first load all of the data required for this project through the Python script load_data.py. We will be using the Yahoo Finance API yfinance to gather a financial database containing the 1 minute interval weekly data for each consituent of the S&P 500. The tickers are located in the file 'tickers.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b697430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Libraries\n",
    "import yfinance as yf\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Start Date\n",
    "start_date = '2024-09-23'\n",
    "# End Date\n",
    "end_date = '2024-09-27'\n",
    "# Time Interval\n",
    "interval = '1m'\n",
    "\n",
    "# Remove existing stock data if it exists\n",
    "if os.path.exists('historical_data'):\n",
    "    shutil.rmtree('historical_data')\n",
    "\n",
    "# Creates historical_data folder to store stock data\n",
    "os.makedirs('historical_data')\n",
    "\n",
    "# Read tickers of S&P 500 holdings from tickers.csv file and store the stock data\n",
    "# retrieved from Yahoo Finance into .csv files in historical data folder\n",
    "with open(\"tickers.csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        ticker = row[0]\n",
    "        \n",
    "        # Format the file name to contain all the relevant information on a stock's historical data including\n",
    "        # the ticker, the start date of data, the end date of data, and the interval of which the data is being\n",
    "        # retrieved. This way the relevant data can easily be accessed in the generate_trades.py file\n",
    "        file_name = ticker + '_' + start_date + '_' + end_date + '_' + interval + '.csv'\n",
    "        \n",
    "        stock_data = yf.download(ticker, start_date, end_date, interval=interval, prepost=False)\n",
    "        stock_data.to_csv('historical_data/' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df3f84",
   "metadata": {},
   "source": [
    "Once the data is loaded into the historical data folder as comma seperated values with each file following the form '[TICKER]_[START_DATE]_[END_DATE].csv', we are ready to load the trading algorithm generate_trades.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc32595",
   "metadata": {},
   "source": [
    "Some of the libraries we will be using include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26833a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Libraries\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c28f241",
   "metadata": {},
   "source": [
    "Where csv will be used to read our stored historical data, plt will be used to plot price by volume charts, pd will be used to create DataFrames for our tables, PdfPages will be used to place our chart and tables into a downloadable pdf, datetime will be used to format the date for our time series, and os will be used to access files/folders within our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46916d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if trade_reports folder exists and remove old financial reports \n",
    "if os.path.exists('trade_reports'):\n",
    "    shutil.rmtree('trade_reports')\n",
    "\n",
    "# Create new trade_reports folder to store new financial reports\n",
    "os.makedirs('trade_reports')    \n",
    "\n",
    "# Loop through all csv files in historical data folder\n",
    "directory = os.fsencode('historical_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae900ba",
   "metadata": {},
   "source": [
    "This is the beginning of our program where we will loop through all the .csv files storing the historical data of each individual stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(directory):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f21341",
   "metadata": {},
   "source": [
    "These are the variables we will be using to generate the trades for each security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a923595",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.fsdecode(file)\n",
    "\n",
    "# Ticker, Start Date, End Date, Interval retrieved from .csv file name\n",
    "ticker = file_name.split('_')[0]\n",
    "start_date = datetime.strptime(file_name.split('_')[1], '%Y-%m-%d').date()\n",
    "end_date = datetime.strptime(file_name.split('_')[2], '%Y-%m-%d').date()\n",
    "interval = file_name.split('_')[3].split('.')[0]\n",
    "\n",
    "# Arrays to store data\n",
    "data = []\n",
    "dates = []\n",
    "price = []\n",
    "volume = []\n",
    "\n",
    "# 50 minute moving average\n",
    "ma_50_minute_price_buildup = 0\n",
    "ma_50_minute_dates = []\n",
    "ma_50_minute_price = []\n",
    "\n",
    "# 200 minute moving average\n",
    "ma_200_minute_price_buildup = 0\n",
    "ma_200_minute_dates = []\n",
    "ma_200_minute_price = []\n",
    "\n",
    "# Intersection Points\n",
    "golden_cross_dates = []\n",
    "golden_cross_price = []\n",
    "death_cross_dates = []\n",
    "death_cross_price = []\n",
    "\n",
    "# Important Characteristics: Min Price, Max Price, Min Volume, Max Volume\n",
    "minPrice = 1e9\n",
    "minPriceDate = -1\n",
    "maxPrice = 0\n",
    "maxPriceDate = -1\n",
    "minVolume = 1e15\n",
    "minVolumeDate = -1\n",
    "maxVolume = 0\n",
    "maxVolumeDate = -1\n",
    "\n",
    "# Market value of position throughout trading \n",
    "initial_market_value = 1000000\n",
    "market_value = initial_market_value\n",
    "long_position = 0\n",
    "short_position = 0\n",
    "\n",
    "# Transaction History to store trades\n",
    "transaction_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90436e94",
   "metadata": {},
   "source": [
    "Read through the historical data within the csv file for each security and transfer the information to its respective array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c725e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read historical data stored within csv file and transfer into python arrays\n",
    "with open('historical_data/'+file_name) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        # Skip first line in .csv file which is a header that describes each column\n",
    "        if (row[1] == 'Open'): continue\n",
    "\n",
    "        # Add data to the respective arrays\n",
    "        dates.append(row[0])\n",
    "        price.append(float(row[1]))\n",
    "        volume.append(float(row[6]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac2da1",
   "metadata": {},
   "source": [
    "Calculate the maximum and minimum price and volume of the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dates)):\n",
    "    # Calculate maximum and minimum price\n",
    "    if minPrice > price[i]:\n",
    "        minPrice = price[i]\n",
    "        minPriceDate = dates[i]\n",
    "    if maxPrice < price[i]:\n",
    "        maxPrice = price[i]\n",
    "        maxPriceDate = dates[i]\n",
    "        \n",
    "    # Calculate maximum and minimum volume\n",
    "    if minVolume > volume[i]:\n",
    "        minVolume = volume[i]\n",
    "        minVolumeDate = dates[i]\n",
    "    if maxVolume < volume[i]:\n",
    "        maxVolume = volume[i]\n",
    "        maxVolumeDate = dates[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed9a20",
   "metadata": {},
   "source": [
    "Calculate the 50 minute and 200 minute moving averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4282cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 50 minute moving average\n",
    "ma_50_minute_price_buildup += price[i]/50\n",
    "# Check that over 50 minutes have elapsed\n",
    "if i >= 50:\n",
    "    ma_50_minute_price_buildup -= price[i-50]/50\n",
    "    ma_50_minute_price.append(ma_50_minute_price_buildup) \n",
    "    ma_50_minute_dates.append(dates[i])\n",
    "    \n",
    "# Calculate 200 minute moving average\n",
    "ma_200_minute_price_buildup += price[i]/200\n",
    "# Check that over 200 minutes have elapsed\n",
    "if i >= 200:\n",
    "    ma_200_minute_price_buildup -= price[i-200]/200\n",
    "    ma_200_minute_price.append(ma_200_minute_price_buildup)\n",
    "    ma_200_minute_dates.append(dates[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a2a39",
   "metadata": {},
   "source": [
    "Look for the Golden Cross (Buy/Cover Signal) and Death Cross (Sell/Short Signal) among the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c578bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golden Cross: 50 minute MA moves above 200 minute MA\n",
    "if ma_50_minute_price[i-50-1] < ma_200_minute_price[i-200-1] and ma_50_minute_price_buildup > ma_200_minute_price_buildup:\n",
    "    # Record transaction date and price for golden cross event\n",
    "    golden_cross_dates.append(dates[i])\n",
    "    golden_cross_price.append(ma_50_minute_price_buildup)\n",
    "    \n",
    "    # Buy Signal if there are no short positions\n",
    "    if short_position == 0:\n",
    "        long_position = market_value/price[i]\n",
    "        transaction_history.append([dates[i], market_value, \"Buy\", price[i], long_position])\n",
    "        market_value = 0\n",
    "    # Cover Signal if there are short positions\n",
    "    else:\n",
    "        market_value -= short_position*price[i]-market_value\n",
    "        short_position = 0\n",
    "        transaction_history.append([dates[i], market_value, \"Cover\", price[i], market_value/price[i]])\n",
    "            \n",
    "# Death Cross: 50 minute MA moves below 200 minute MA\n",
    "if ma_50_minute_price[i-50-1] > ma_200_minute_price[i-200-1] and ma_50_minute_price_buildup < ma_200_minute_price_buildup:\n",
    "    # Record transaction date and price for death cross event\n",
    "    death_cross_dates.append(dates[i])\n",
    "    death_cross_price.append(ma_50_minute_price_buildup)\n",
    "    \n",
    "    # Sell Signal if there is a long positions\n",
    "    if long_position == 0:\n",
    "        short_position = market_value/price[i]\n",
    "        transaction_history.append([dates[i], market_value, \"Short\", price[i], short_position])\n",
    "    # Short Signal if there are no long positions\n",
    "    else:\n",
    "        market_value = long_position*price[i]\n",
    "        long_position = 0\n",
    "        transaction_history.append([dates[i], market_value, \"Sell\", price[i], market_value/price[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654afc59",
   "metadata": {},
   "source": [
    "Setup the chart and table to be placed into a downloadable pdf document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PdfPages('trade_reports/'+file_name.split('.')[0]+'.pdf')\n",
    "fig = plt.figure(dpi=100)\n",
    "\n",
    "# Plot Charts. Grey = Price. Orange = 50 minute MA. Blue = 200 minute MA. \n",
    "plt.title(ticker + \" \" + str(start_date) + \" \" + str(end_date) + \" \" + interval)\n",
    "\n",
    "# ax1 subplot will be used to plot all price related graphs\n",
    "ax1 = plt.subplot()\n",
    "ax1.set_xlabel('Date', fontsize=8)\n",
    "ax1.set_ylabel('Price', fontsize=8)\n",
    "\n",
    "# Give graph some room at the bottom and top to prevent entire chart from being spread too wide\n",
    "ax1.set_ylim(0.995*minPrice, 1.005*maxPrice)\n",
    "ax1.yaxis.set_tick_params(labelsize=6)\n",
    "\n",
    "# ax2 subplot will be used to plot all volume related graphs\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Volume', fontsize=8)\n",
    "ax2.set_ylim(0, 5*maxVolume)\n",
    "ax2.yaxis.set_tick_params(labelsize=6)\n",
    "\n",
    "# Plot stock price\n",
    "ax1.plot(dates, price, color='silver', linewidth=0.75) \n",
    "# Plot 50 minute moving average line\n",
    "ax1.plot(ma_50_minute_dates, ma_50_minute_price, color='darkorange', linewidth=0.75)\n",
    "# Plot 200 minute moving average line\n",
    "ax1.plot(ma_200_minute_dates, ma_200_minute_price, color='darkblue', linewidth=0.75)\n",
    "# Plot golden cross intersection points\n",
    "ax1.plot(golden_cross_dates, golden_cross_price, 'g^', markersize=3)\n",
    "# Plot death cross intersection points\n",
    "ax1.plot(death_cross_dates, death_cross_price, 'rv', markersize=3)\n",
    "\n",
    "ax2.bar(dates, volume, width=1.0, color='cornflowerblue')\n",
    "\n",
    "ax1.xaxis.set_visible(False)\n",
    "\n",
    "pdf.savefig(fig)\n",
    "\n",
    "# Check if there are intersections of the moving averages. If there are no intersections, do not\n",
    "# add a table in the second page detailing the intersection dates. \n",
    "if (len(transaction_history) > 0):\n",
    "    plt.clf()\n",
    "    plt.title(ticker + \" \" + str(start_date) + \" \" + str(end_date) + \" \" + interval)\n",
    "\n",
    "    df = pd.DataFrame(transaction_history)    \n",
    "    df.columns = [\"Date\", 'Market Value', 'Action', 'Price', '# Shares']\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.table(cellText=df.values, colLabels=df.columns, loc='center')\n",
    "\n",
    "    pdf.savefig(fig)\n",
    "    \n",
    "pdf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
