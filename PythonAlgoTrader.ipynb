{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e2c527-caa5-4fd9-8643-db682d89ade0",
   "metadata": {},
   "source": [
    "# Python AlgoTrader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88728f7-533a-4492-9352-61c891a324af",
   "metadata": {},
   "source": [
    "### Created By: Aaron Gao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593a096-8ebf-4d95-8db9-ef767bb09d87",
   "metadata": {},
   "source": [
    "Python AlgoTrader is an automated trading system that executes orders based on the crossover of the 50 minute and 200 minute moving average. By watching out for the iconic Golden Cross and the infamous Death Cross, intraday traders can find great opportunities for riding out momentum on breakout trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37eabd",
   "metadata": {},
   "source": [
    "We will first load all of the data required for this project through the Python script load_data.py. We will be using the Yahoo Finance API yfinance to gather a financial database containing the 1 minute interval weekly data for each consituent of the S&P 500. The tickers are located in the file 'tickers.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b697430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import csv\n",
    "\n",
    "start_date = '2024-09-09'\n",
    "end_date = '2024-09-16'\n",
    "interval = '1m'\n",
    "data = []\n",
    "\n",
    "with open(\"tickers.csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "\n",
    "for row in data:\n",
    "    ticker = row[0]\n",
    "    file_name = ticker + '_' + start_date + '_' + end_date + '.csv'\n",
    "    data = yf.download(tickers=ticker, start=start_date, end=end_date, interval=interval, prepost=False)\n",
    "    data.to_csv('historical_data/'+file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df3f84",
   "metadata": {},
   "source": [
    "Once the data is loaded into the historical data folder as comma seperated values with each file following the form '[TICKER]_[START_DATE]_[END_DATE].csv', we are ready to load the trading algorithm generate_trades.py. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc32595",
   "metadata": {},
   "source": [
    "Some of the libraries we will be using include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26833a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Libraries\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from datetime import date, timedelta, datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c28f241",
   "metadata": {},
   "source": [
    "Where csv will be used to read our stored historical data, plt will be used to plot price by volume charts, pd will be used to create DataFrames for our tables, PdfPages will be used to place our chart and tables into a downloadable pdf, datetime will be used to format the date for our time series, and os will be used to access files/folders within our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46916d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all csv files in historical data folder\n",
    "directory = os.fsencode('historical_data')\n",
    "for file in os.listdir(directory):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae900ba",
   "metadata": {},
   "source": [
    "This is the beginning of our program where we will loop through all the .csv files storing the historical data of each individual stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # Variables\n",
    "    filename = os.fsdecode(file)\n",
    "    ticker = filename.split('_')[0]\n",
    "    #ticker = filename.split('_')[0]\n",
    "    start_date = datetime.strptime(filename.split('_')[1], '%Y-%m-%d').date()\n",
    "    end_date = datetime.strptime(filename.split('_')[2].split('.')[0], '%Y-%m-%d').date()\n",
    "    file_name = ticker + '_' + str(start_date) + '_' + str(end_date) + '.csv'\n",
    "    data = []\n",
    "    dates = []\n",
    "    price = []\n",
    "    volume = []\n",
    "    ma_50_minute_price_buildup = 0\n",
    "    ma_50_minute_dates = []\n",
    "    ma_50_minute_price = []\n",
    "    ma_200_minute_price_buildup = 0\n",
    "    ma_200_minute_dates = []\n",
    "    ma_200_minute_price = []\n",
    "    golden_cross_dates = []\n",
    "    golden_cross_price = []\n",
    "    death_cross_dates = []\n",
    "    death_cross_price = []\n",
    "    minPrice = 1e9\n",
    "    minPriceDate = -1\n",
    "    maxPrice = 0\n",
    "    maxPriceDate = -1\n",
    "    minVolume = 1e15\n",
    "    minVolumeDate = -1\n",
    "    maxVolume = 0\n",
    "    maxVolumeDate = -1\n",
    "    initial_market_value = 1000000\n",
    "    market_value = initial_market_value\n",
    "    long_position = 0\n",
    "    short_position = 0\n",
    "    transaction_history = []\n",
    "    interval = '1m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f21341",
   "metadata": {},
   "source": [
    "These are the variables we will be using to generate the trades for each security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a923595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read historical data stored within csv file and transfer into an array\n",
    "with open('historical_data/'+file_name) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "for i in range(1, len(data)):\n",
    "    dates.append(data[i][0])\n",
    "    price.append(float(data[i][1]))\n",
    "    volume.append(float(data[i][6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90436e94",
   "metadata": {},
   "source": [
    "Read through the historical data within the csv file for each security and transfer the information to its respective array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c725e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dates)):\n",
    "    # Calculate maximum and minimum price\n",
    "    if minPrice > price[i]:\n",
    "        minPrice = price[i]\n",
    "        minPriceDate = dates[i]\n",
    "    if maxPrice < price[i]:\n",
    "        maxPrice = price[i]\n",
    "        maxPriceDate = dates[i]\n",
    "        \n",
    "    # Calculate maximum and minimum volume\n",
    "    if minVolume > volume[i]:\n",
    "        minVolume = volume[i]\n",
    "        minVolumeDate = dates[i]\n",
    "    if maxVolume < volume[i]:\n",
    "        maxVolume = volume[i]\n",
    "        maxVolumeDate = dates[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac2da1",
   "metadata": {},
   "source": [
    "Calculate the maximum and minimum price and volume of the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beb11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 50 minute and 200 minute moving averages\n",
    "ma_50_minute_price_buildup += price[i]/50\n",
    "if i >= 50:\n",
    "    ma_50_minute_price_buildup -= price[i-50]/50\n",
    "    ma_50_minute_price.append(ma_50_minute_price_buildup) \n",
    "    ma_50_minute_dates.append(dates[i])\n",
    "    \n",
    "ma_200_minute_price_buildup += price[i]/200\n",
    "if i >= 200:\n",
    "    ma_200_minute_price_buildup -= price[i-200]/200\n",
    "    ma_200_minute_price.append(ma_200_minute_price_buildup)\n",
    "    ma_200_minute_dates.append(dates[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed9a20",
   "metadata": {},
   "source": [
    "Calculate the 50 minute and 200 minute moving averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4282cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Golden Cross: 50 minute MA moves above 200 minute MA\n",
    "if ma_50_minute_price[i-50-1] < ma_200_minute_price[i-200-1] and ma_50_minute_price_buildup > ma_200_minute_price_buildup:\n",
    "    golden_cross_dates.append(dates[i])\n",
    "    golden_cross_price.append(ma_50_minute_price_buildup)\n",
    "    # Buy/Cover Signal\n",
    "    if short_position == 0:\n",
    "        long_position = market_value/price[i]\n",
    "        transaction_history.append([dates[i], market_value, \"Buy\", price[i], long_position])\n",
    "        market_value = 0\n",
    "    else:\n",
    "        market_value -= short_position*price[i]-market_value\n",
    "        short_position = 0\n",
    "        transaction_history.append([dates[i], market_value, \"Cover\", price[i], market_value/price[i]])\n",
    "            \n",
    "# Death Cross: 50 minute MA moves below 200 minute MA\n",
    "if ma_50_minute_price[i-50-1] > ma_200_minute_price[i-200-1] and ma_50_minute_price_buildup < ma_200_minute_price_buildup:\n",
    "    death_cross_dates.append(dates[i])\n",
    "    death_cross_price.append(ma_50_minute_price_buildup)\n",
    "    # Sell/Short Signal\n",
    "    if long_position == 0:\n",
    "        short_position = market_value/price[i]\n",
    "        transaction_history.append([dates[i], market_value, \"Short\", price[i], short_position])\n",
    "    else:\n",
    "        market_value = long_position*price[i]\n",
    "        long_position = 0\n",
    "        transaction_history.append([dates[i], market_value, \"Sell\", price[i], market_value/price[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a2a39",
   "metadata": {},
   "source": [
    "Look for the Golden Cross (Buy/Cover Signal) and Death Cross (Sell/Short Signal) among the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c578bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PdfPages('trade_reports/'+file_name.split('.')[0]+'.pdf')\n",
    "fig = plt.figure(dpi=100)\n",
    "\n",
    "# Setup ticks along the x and y axis to maximize chart readability and accuracy\n",
    "xticks = [str(start_date+timedelta(days=x))+' 09:30:00-04:00' for x in range(6)]\n",
    "\n",
    "# Plot Charts. Grey = Price. Orange = 50 minute MA. Blue = 200 minute MA. \n",
    "plt.title(ticker+\" \"+str(start_date)+\" \"+str(end_date)+\" \"+interval)\n",
    "ax1 = plt.subplot()\n",
    "ax1.set_xlabel('Date', fontsize=8)\n",
    "ax1.set_ylabel('Price', fontsize=8)\n",
    "ax1.set_ylim(0.9*minPrice, 1.1*maxPrice)\n",
    "ax1.yaxis.set_tick_params(labelsize=6)\n",
    "ax1.xaxis.set_tick_params(labelsize=6)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Volume', fontsize=8)\n",
    "ax2.set_ylim(0, 5*maxVolume)\n",
    "ax2.yaxis.set_tick_params(labelsize=6)\n",
    "\n",
    "# Format chart axis and line width\n",
    "ax1.plot(dates, price, color='silver', linewidth=0.75) \n",
    "ax1.plot(ma_50_minute_dates, ma_50_minute_price, color='darkorange', linewidth=0.75)\n",
    "ax1.plot(ma_200_minute_dates, ma_200_minute_price, color='darkblue', linewidth=0.75)\n",
    "ax1.plot(golden_cross_dates, golden_cross_price, 'g^', markersize=3)\n",
    "ax1.plot(death_cross_dates, death_cross_price, 'rv', markersize=3)\n",
    "\n",
    "ax2.bar(dates, volume, width=1.0, color='cornflowerblue')\n",
    "\n",
    "ax1.set_xticks(xticks)\n",
    "ax1.set_xticklabels([x.split(' ')[0] for x in xticks])\n",
    "\n",
    "pdf.savefig(fig)\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.title(ticker+\" \"+str(start_date)+\" \"+str(end_date)+\" \"+interval)\n",
    "df = pd.DataFrame(transaction_history)\n",
    "df.columns = [\"Date\", 'Market Value', 'Action', 'Price', '# Shares']\n",
    "\n",
    "plt.axis('off')\n",
    "plt.table(cellText=df.values, colLabels=df.columns, loc='center')\n",
    "\n",
    "pdf.savefig(fig)\n",
    "pdf.close()\n",
    "except:\n",
    "print(file + \" had an unknown error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654afc59",
   "metadata": {},
   "source": [
    "Setup the chart and table to be placed into a downloadable pdf document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
